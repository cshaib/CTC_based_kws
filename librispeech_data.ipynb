{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import librosa \n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhonemeTokenizer:\n",
    "# tokenize phonemes into IDs  \n",
    "    def __init__(self, phoneme_to_phoneme_index):\n",
    "        self.phoneme_to_phoneme_index = phoneme_to_phoneme_index\n",
    "        self.phoneme_index_to_phoneme = {v: k for k, v in self.phoneme_to_phoneme_index.items()}\n",
    "\n",
    "    def EncodeAsIds(self, phoneme_string):\n",
    "        return [self.phoneme_to_phoneme_index[p] for p in phoneme_string.split()]\n",
    "\n",
    "    def DecodeIds(self, phoneme_ids):\n",
    "        return \" \".join([self.phoneme_index_to_phoneme[id] for id in phoneme_ids])\n",
    "    \n",
    "# label_set = [1: 'AA0', 'AA1', 'AA2', 'AE0', 'AE1', 'AE2', 'AH0', 'AH1', 'AH2', 'AO0', 'AO1', 'AO2', \\\n",
    "#              'AW0', 'AW1', 'AW2', 'AY0', 'AY1', 'AY2', 'EH0', 'EH1', 'EH2', 'ER0', 'ER1', 'ER2', \\\n",
    "#              'EY0', 'EY1', 'EY2', 'IH0', 'IH1', 'IH2', 'IY0', 'IY1', 'IY2', 'OW0', 'OW1', 'OW2', \\\n",
    "#              'OY0', 'OY1', 'OY2', 'UH0', 'UH1', 'UH2', 'UW0', 'UW1', 'UW2', \\\n",
    "#              'B', 'CH', 'D', 'DH', 'F', 'G', 'HH', 'JH', 'K', 'L', 'M', 'N', 'NG', 'P', 'R', \\\n",
    "#              'S', 'SH', 'T', 'TH', 'V', 'W', 'Y', 'Z', 'ZH', 'sil', 'sp', '']\n",
    "\n",
    "label_set = ['AA', 'AE', 'AH', 'AO', 'AW', 'AY', 'B', 'CH', 'D', 'DH', 'EH', 'ER', 'EY', 'F', 'G', 'HH',\n",
    "             'IH', 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'OY', 'P', 'R', 'S', 'SH', 'T', 'TH', 'UH',\n",
    "             'UW', 'V', 'W', 'Y', 'Z', 'ZH', 'SIL', 'SPN', '']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from fileinput import FileInput\n",
    "mod_lines = []\n",
    "\n",
    "for f in os.listdir(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/train/\"):\n",
    "    if f.endswith(\".txt\"):\n",
    "        with open(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/train/\"+f, \"r\") as input_file:\n",
    "            for line in input_file:\n",
    "                mod_lines.append(re.sub(r\"(\\d.*-\\d.*-\\d\\d\\d\\d)\", r\"\\1,\", line))\n",
    "        with open(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/train/\"+f, \"w\") as output_file:\n",
    "            for line in mod_lines:\n",
    "                output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_lines = []\n",
    "for f in os.listdir(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/test/\"):\n",
    "    if f.endswith(\".txt\"):\n",
    "        with open(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/test/\"+f, \"r\") as input_file:\n",
    "            for line in input_file:\n",
    "                mod_lines.append(re.sub(r\"(\\d.*-\\d.*-\\d\\d\\d\\d)\", r\"\\1,\", line))\n",
    "        with open(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/test/\"+f, \"w\") as output_file:\n",
    "            for line in mod_lines:\n",
    "                output_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Train transcript: \n\n                 0                                                  1\n0  2136-5147-0000   LADY KNOLLYS PURSUED HER ENQUIRIES AND WHY DO...\n1  2136-5147-0001   SHE IS MY GOVERNESS A FINISHING GOVERNESS MIS...\n2  2136-5147-0002   BUT SHE IS ILL I ANSWERED AND ALL THIS TIME I...\n3  2136-5147-0003   IS SHE UP OR IN BED IN HER ROOM BUT NOT IN BE...\n4  2136-5147-0004   BUT SHE MAY ALSO BE ABOUT THE MOST PERNICIOUS...\n\n\n Dev transcript: \n\n                   0                                                  1\n0  7850-281318-0000   SOME ARE WONDERFULLY WROUGHT PRETTY LITTLE HO...\n1  7850-281318-0001   INDEED IT IS NOT A NEST AT ALL ONLY THE BEGIN...\n2  7850-281318-0002   AND THERE IS AN OLD STORY ABOUT THIS WHICH I ...\n3  7850-281318-0003                     OH WHAT SHALL WE DO FOR A HOME\n4  7850-281318-0004   AND THE POOR SILLY THINGS RUFFLED UP THEIR FE...\n"
    }
   ],
   "source": [
    "# load in transcripts of training data\n",
    "train_transcript = pd.DataFrame()\n",
    "for f in os.listdir(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/train\"):\n",
    "    if f.endswith(\".txt\"):\n",
    "        data = pd.read_csv(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/train/\"+f, header=None)\n",
    "        train_transcript = pd.concat([train_transcript, data])\n",
    "\n",
    "# train_transcript.drop(1, axis=1, inplace=True)\n",
    "print(f'Train transcript: \\n\\n {train_transcript.head()}')\n",
    "\n",
    "# load in transcripts of dev data \n",
    "dev_transcript = pd.DataFrame()\n",
    "for f in os.listdir(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/test\"):\n",
    "    if f.endswith(\".txt\"):\n",
    "        data = pd.read_csv(\"/Users/chantal/Desktop/StMichaels/unpacked_labels/test/\"+f, header=None)\n",
    "        dev_transcript = pd.concat([dev_transcript, data])\n",
    "\n",
    "# dev_transcript.drop(1, axis=1, inplace=True)\n",
    "print(f'\\n\\n Dev transcript: \\n\\n {dev_transcript.head()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n===Keywords===\nknit 0.856\nmistook 0.846\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "\n",
    "# identify keywords using tf-idf \n",
    "corpus_train = train_transcript[1].tolist()\n",
    "\n",
    "cv = CountVectorizer()\n",
    "word_count_vec = cv.fit_transform(corpus_train)\n",
    "tfidf_transformer.fit(word_count_vec)\n",
    "\n",
    "feature_names = cv.get_feature_names()\n",
    "\n",
    "tf_idf_vector = tfidf_transformer.transform(cv.transform(corpus_train))\n",
    "\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "keywords = extract_topn_from_vector(feature_names, sorted_items, 20)\n",
    "\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k, keywords[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7850-281318-0000</td>\n      <td>SOME ARE WONDERFULLY WROUGHT PRETTY LITTLE HO...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7850-281318-0001</td>\n      <td>INDEED IT IS NOT A NEST AT ALL ONLY THE BEGIN...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7850-281318-0002</td>\n      <td>AND THERE IS AN OLD STORY ABOUT THIS WHICH I ...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7850-281318-0003</td>\n      <td>OH WHAT SHALL WE DO FOR A HOME</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7850-281318-0004</td>\n      <td>AND THE POOR SILLY THINGS RUFFLED UP THEIR FE...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>146</th>\n      <td>7850-286674-0013</td>\n      <td>HERE COMES THE SNAPPING TURTLE</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>147</th>\n      <td>7850-286674-0014</td>\n      <td>SURE ENOUGH THERE HE CAME THROUGH THE SHALLOW...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>7850-286674-0015</td>\n      <td>THEY THOUGHT HE MIGHT BE GOING TO TAKE A NAP ...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>149</th>\n      <td>7850-286674-0016</td>\n      <td>HE BEGAN TO DRAW IN HIS LEGS VERY VERY SLOWLY...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>150</th>\n      <td>7850-286674-0017</td>\n      <td>THE NYMPHS HAD ALREADY GOTTEN AWAY</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n<p>476 rows Ã— 3 columns</p>\n</div>",
      "text/plain": "                    0                                                  1  2\n0    7850-281318-0000   SOME ARE WONDERFULLY WROUGHT PRETTY LITTLE HO... -1\n1    7850-281318-0001   INDEED IT IS NOT A NEST AT ALL ONLY THE BEGIN... -1\n2    7850-281318-0002   AND THERE IS AN OLD STORY ABOUT THIS WHICH I ... -1\n3    7850-281318-0003                     OH WHAT SHALL WE DO FOR A HOME -1\n4    7850-281318-0004   AND THE POOR SILLY THINGS RUFFLED UP THEIR FE... -1\n..                ...                                                ... ..\n146  7850-286674-0013                     HERE COMES THE SNAPPING TURTLE -1\n147  7850-286674-0014   SURE ENOUGH THERE HE CAME THROUGH THE SHALLOW... -1\n148  7850-286674-0015   THEY THOUGHT HE MIGHT BE GOING TO TAKE A NAP ... -1\n149  7850-286674-0016   HE BEGAN TO DRAW IN HIS LEGS VERY VERY SLOWLY... -1\n150  7850-286674-0017                 THE NYMPHS HAD ALREADY GOTTEN AWAY -1\n\n[476 rows x 3 columns]"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find top keywords in train dataset, mark them in the dev dataset\n",
    "keyword = \"mistook\"\n",
    "\n",
    "dev_transcript[2] = dev_transcript[1].str.find(keyword)\n",
    "\n",
    "dev_transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chantal/Desktop/systematic_review/abstract_env/lib/python3.7/site-packages/librosa/filters.py:239: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  \"Empty filters detected in mel frequency basis. \"\n"
     ]
    }
   ],
   "source": [
    "# load in audio data in train set \n",
    "\n",
    "audio_path = \"/Users/chantal/Desktop/StMichaels/unpacked/\"\n",
    "data = os.listdir(audio_path)\n",
    "\n",
    "label_path = \"/Users/chantal/Desktop/StMichaels/mini-librispeech-csv/train_data.csv\"\n",
    "\n",
    "all_data = {}\n",
    "\n",
    "# load in the audio and get mfcc features for each audio \n",
    "for item in data: \n",
    "    if item.endswith(\".flac\"):\n",
    "        y, sr = librosa.load(audio_path+item)\n",
    "        feat = librosa.feature.mfcc(y, sr, n_mfcc=30, n_fft=25, hop_length=10)\n",
    "        all_data[item[:-5]] = feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1519 1519 1519\n"
     ]
    }
   ],
   "source": [
    "# load in the labels\n",
    "label_df = pd.read_csv(label_path)\n",
    "phoneme_df = label_df['phonemes_39'].tolist()\n",
    "l = []\n",
    "n = []\n",
    "v = []\n",
    "\n",
    "for (key, value), label in zip(all_data.items(), phoneme_df):\n",
    "    int_label = [label_set.index(x.upper()) for x in label.split()]\n",
    "    l.append(int_label)\n",
    "    n.append(key)\n",
    "    v.append(value)\n",
    "    \n",
    "# save down data in pandas dataframe format: filename - data - labels for train, test, and dev. \n",
    "print(len(n), len(v), len(l))\n",
    "df = pd.DataFrame({'name': n, 'audio': v, 'label':l})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1000:].to_pickle(\"all_train_audio_2\",  compression='gzip', protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['audio'][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
<<<<<<< HEAD
  }
 ],
=======
  },
>>>>>>> 17128019a8ac183602441fc6b6e455cd1abccf88
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.1 64-bit ('donut': virtualenv)",
   "language": "python",
   "name": "python36164bitdonutvirtualenv17829ec4bb11427b84ed8ea016c3a586"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
